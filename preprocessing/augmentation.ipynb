{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in d:\\anaconda3\\envs\\miti_pytorch\\lib\\site-packages (2.4.0+cu121)\n",
      "Requirement already satisfied: torchvision in d:\\anaconda3\\envs\\miti_pytorch\\lib\\site-packages (0.19.0+cu121)\n",
      "Requirement already satisfied: torchaudio in d:\\anaconda3\\envs\\miti_pytorch\\lib\\site-packages (2.4.0+cu121)\n",
      "Requirement already satisfied: filelock in d:\\anaconda3\\envs\\miti_pytorch\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\anaconda3\\envs\\miti_pytorch\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in d:\\anaconda3\\envs\\miti_pytorch\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in d:\\anaconda3\\envs\\miti_pytorch\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda3\\envs\\miti_pytorch\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda3\\envs\\miti_pytorch\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda3\\envs\\miti_pytorch\\lib\\site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: numpy in d:\\anaconda3\\envs\\miti_pytorch\\lib\\site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\anaconda3\\envs\\miti_pytorch\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda3\\envs\\miti_pytorch\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda3\\envs\\miti_pytorch\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations import Compose, HorizontalFlip, RandomRotate90, ColorJitter, RandomCrop, GaussianBlur, Normalize\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import os.path\n",
    "from PIL import Image, ImageDraw\n",
    "from sahi.utils.file import load_json, save_json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchvision\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.is_available()\n",
    "torch.cuda.current_device()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cassette1_train_corrected_coco.json\n",
      "cassette1_train_sliced_coco.json\n",
      "..\\data\\augmentation\n",
      "Original Annotation: .\\data\\coco\\cassette1_train_corrected_coco.json\n",
      "Sliced Annotation:  .\\data\\coco\\cassette1_train_sliced_coco.json\n",
      ".\\data\\coco\\images\n",
      ".\\data\\coco\\images_sliced\\cassette1_train\n"
     ]
    }
   ],
   "source": [
    "coco_file_name = \"cassette1_train\"\n",
    "\n",
    "original_file = f\"{coco_file_name}_corrected_coco.json\"\n",
    "sliced_file = f\"{coco_file_name}_sliced_coco.json\"\n",
    "\n",
    "print(original_file)\n",
    "print(sliced_file)\n",
    "\n",
    "# Define paths\n",
    "DATA_DIR = os.path.join(\".\", \"data\", \"coco\")\n",
    "ORG_ANNOTATION_PATH = os.path.join(DATA_DIR, original_file)\n",
    "SLC_ANNOTATION_PATH  = os.path.join(DATA_DIR, sliced_file)\n",
    "AUGMENTATION_PATH =  os.path.join(\"..\", \"data\",\"augmentation\")\n",
    "\n",
    "IMAGE_DIR = os.path.join(DATA_DIR, \"images\") \n",
    "SLICED_IMAGE_DIR = os.path.join(DATA_DIR, \"images_sliced\",coco_file_name) \n",
    "VISUALIZATION_DIR = os.path.join(\".\", \"data\", \"bbox_vis\")\n",
    "BBOX_VISUALISATION_DIR = os.path.join\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(AUGMENTATION_PATH, exist_ok=True)\n",
    "\n",
    "print(AUGMENTATION_PATH)\n",
    "print(\"Original Annotation:\", ORG_ANNOTATION_PATH)\n",
    "print(\"Sliced Annotation: \", SLC_ANNOTATION_PATH)\n",
    "\n",
    "print(IMAGE_DIR)\n",
    "print(SLICED_IMAGE_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.\\\\data\\\\coco\\\\cassette1_train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m coco_dict \u001b[38;5;241m=\u001b[39m \u001b[43mload_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mANNOTATION_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m [img\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: img[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]}) \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m coco_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m      3\u001b[0m save_json(coco_dict, save_path\u001b[38;5;241m=\u001b[39mNEW_AUGMENTATION_PATH)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sahi\\utils\\file.py:69\u001b[0m, in \u001b[0;36mload_json\u001b[1;34m(load_path, encoding)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03mLoads json formatted data (given as \"data\") from load_path\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;124;03mEncoding type can be specified with 'encoding' argument\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    load_path: \"dirname/coco.json\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# read from path\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mload_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[0;32m     70\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(json_file)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.\\\\data\\\\coco\\\\cassette1_train.json'"
     ]
    }
   ],
   "source": [
    "coco_dict = load_json(ORG)\n",
    "[img.update({\"file_name\": img[\"file_name\"].split(\"/\")[-1]}) for img in coco_dict[\"images\"]]\n",
    "save_json(coco_dict, save_path=NEW_AUGMENTATION_PATH)\n",
    "\n",
    "coco_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'coco_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcoco_dict\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m      2\u001b[0m     fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m9\u001b[39m), constrained_layout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m     mono_img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(IMAGE_DIR, img[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'coco_dict' is not defined"
     ]
    }
   ],
   "source": [
    "for img in coco_dict[\"images\"]:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 9), constrained_layout=True)\n",
    "\n",
    "    mono_img = Image.open(os.path.join(IMAGE_DIR, img[\"file_name\"])).convert(\"L\")\n",
    "    rgb_img = Image.merge(\"RGB\", (mono_img, mono_img, mono_img))\n",
    "\n",
    "    # iterate over all annotations\n",
    "    for ann_ind in range(len(coco_dict[\"annotations\"])):\n",
    "        \n",
    "        if coco_dict[\"annotations\"][ann_ind][\"image_id\"] == img[\"id\"]:\n",
    "            # convert coco bbox to pil bbox\n",
    "            xywh = coco_dict[\"annotations\"][ann_ind][\"bbox\"]\n",
    "            xyxy = [xywh[0], xywh[1], xywh[0]+xywh[2], xywh[1]+xywh[3]]\n",
    "\n",
    "            # visualize bbox over image\n",
    "            ImageDraw.Draw(rgb_img).rectangle(xyxy, width=5, outline=\"lime\")\n",
    "\n",
    "    ax.axis(\"off\")\n",
    "    ax.imshow(rgb_img)\n",
    "    fig.savefig(os.path.join(BBOX_VISUALIZATION_DIR, img[\"file_name\"][:-4] + \".png\"))\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.cla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefectAugmentationPipeline:\n",
    "    def __init__(self, scale_classification):\n",
    "        self.scale_classification = scale_classification\n",
    "        self.augmentations_small, self.augmentations_large = self.define_augmentations()\n",
    "\n",
    "    def define_augmentations(self):\n",
    "        # Define augmentations for small and large scale\n",
    "        augmentations_small = A.Compose([\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.Rotate(limit=90, p=0.5),\n",
    "            A.RandomBrightnessContrast(p=0.3),\n",
    "            A.GaussianBlur(blur_limit=(3, 5), p=0.3),\n",
    "            A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
    "            ToTensorV2(),\n",
    "        ], bbox_params=A.BboxParams(format='coco', label_fields=['class_labels']))\n",
    "\n",
    "        augmentations_large = A.Compose([\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.Rotate(limit=45, p=0.5),\n",
    "            A.RandomBrightnessContrast(p=0.5),\n",
    "            A.GaussianBlur(blur_limit=(5, 7), p=0.3),\n",
    "            ToTensorV2(),\n",
    "        ], bbox_params=A.BboxParams(format='coco', label_fields=['class_labels']))\n",
    "\n",
    "        return augmentations_small, augmentations_large\n",
    "\n",
    "    def get_scale_type(self, defect_types):\n",
    "        # Determine predominant scale based on defect types\n",
    "        return \"small\" if any(\n",
    "            self.scale_classification.get(dt, \"Small Scale\") == \"Small Scale\" for dt in defect_types\n",
    "        ) else \"large\"\n",
    "\n",
    "    def augment_image(self, image, bboxes, class_labels, defect_types):\n",
    "        # Choose augmentation based on scale\n",
    "        predominant_scale = self.get_scale_type(defect_types)\n",
    "        augmentation = self.augmentations_small if predominant_scale == \"small\" else self.augmentations_large\n",
    "        \n",
    "        # Apply augmentation\n",
    "        augmented = augmentation(image=image, bboxes=bboxes, class_labels=class_labels)\n",
    "        return augmented['image'], augmented['bboxes']\n",
    "\n",
    "    def prepare_image(self, image_path):\n",
    "        # Load and convert image to compatible format for albumentations\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if image is None:\n",
    "            raise ValueError(\"Failed to load image. Check the file path and format.\")\n",
    "        return cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)  # Convert to 3-channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MITI_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
