{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in d:\\anaconda3\\envs\\miti_pytorch\\lib\\site-packages (2.4.0+cu121)\n",
      "Requirement already satisfied: torchvision in d:\\anaconda3\\envs\\miti_pytorch\\lib\\site-packages (0.19.0+cu121)\n",
      "Requirement already satisfied: torchaudio in d:\\anaconda3\\envs\\miti_pytorch\\lib\\site-packages (2.4.0+cu121)\n",
      "Requirement already satisfied: filelock in d:\\anaconda3\\envs\\miti_pytorch\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\anaconda3\\envs\\miti_pytorch\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in d:\\anaconda3\\envs\\miti_pytorch\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in d:\\anaconda3\\envs\\miti_pytorch\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda3\\envs\\miti_pytorch\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda3\\envs\\miti_pytorch\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda3\\envs\\miti_pytorch\\lib\\site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: numpy in d:\\anaconda3\\envs\\miti_pytorch\\lib\\site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\anaconda3\\envs\\miti_pytorch\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda3\\envs\\miti_pytorch\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda3\\envs\\miti_pytorch\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations import Compose, HorizontalFlip, RandomRotate90, ColorJitter, RandomCrop, GaussianBlur, Normalize\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import os.path\n",
    "from PIL import Image, ImageDraw\n",
    "from sahi.utils.file import load_json, save_json\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "\n",
    "import torchvision\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.is_available()\n",
    "torch.cuda.current_device()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths verified.\n"
     ]
    }
   ],
   "source": [
    "split = \"train\"  # or \"val\" as required\n",
    "coco_file_name = \"cassette1_\" + split\n",
    "original_file = f\"{coco_file_name}_corrected_coco.json\"\n",
    "sliced_file = f\"{coco_file_name}_sliced_coco.json\"\n",
    "\n",
    "# Path setup\n",
    "DATA_DIR = os.path.join(\"..\", \"data\")\n",
    "DATA_COCO_DIR = os.path.join(DATA_DIR, \"coco\")\n",
    "\n",
    "AUGMENTATION_PATH = os.path.join(DATA_DIR, \"augmentation\")\n",
    "IMAGE_DIR = os.path.join(DATA_COCO_DIR, \"images\")\n",
    "SLICED_IMAGE_DIR = os.path.join(DATA_COCO_DIR, \"images_sliced\", coco_file_name)\n",
    "VISUALISATION_DIR = os.path.join(DATA_DIR, \"bbox_vis\")\n",
    "VISUALISATION_FILE = os.path.join(VISUALISATION_DIR, coco_file_name)\n",
    "\n",
    "# Update paths for original and sliced annotations based on split\n",
    "ORG_ANNOTATION_PATH = os.path.join(DATA_COCO_DIR, split, original_file)\n",
    "SLC_ANNOTATION_PATH = os.path.join(DATA_COCO_DIR, split, sliced_file)\n",
    "\n",
    "os.path.exists(DATA_DIR)\n",
    "os.path.exists(ORG_ANNOTATION_PATH)\n",
    "\n",
    "for path in [DATA_DIR, AUGMENTATION_PATH, IMAGE_DIR, SLICED_IMAGE_DIR, VISUALISATION_DIR]:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "print(\"Paths verified.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Mainly for COCO files. Not catered for YOLO\n",
    "'''\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from tqdm import tqdm\n",
    "from sahi.utils.file import load_json\n",
    "\n",
    "# Define the main COCO file name\n",
    "coco_file_name = \"cassette1_train\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAugmentor:\n",
    "    def __init__(self, coco_file_name, config, split=\"train\", image_type=\"original\"):\n",
    "        self.split = split\n",
    "        self.coco_file_name = coco_file_name\n",
    "        self.config = config\n",
    "        self.image_type = image_type\n",
    "\n",
    "        self.DATA_DIR = config.get(\"DATA_DIR\", \"../data\")\n",
    "        self.AUGMENTATION_PATH = config.get(\"AUGMENTATION_PATH\", os.path.join(self.DATA_DIR, \"augmentation\"))\n",
    "        self.VISUALIZATION_DIR = config.get(\"VISUALIZATION_DIR\", os.path.join(self.DATA_DIR, \"bbox_vis\"))\n",
    "\n",
    "        image_subdir = \"original_images\" if self.image_type == \"original\" else \"sliced_images\"\n",
    "        self.output_dir = os.path.join(self.AUGMENTATION_PATH, image_subdir, f\"{split}_images\")\n",
    "        self.bbox_vis_dir = os.path.join(self.VISUALIZATION_DIR, coco_file_name, image_subdir)\n",
    "\n",
    "        self.org_annotation_path = os.path.join(self.DATA_DIR, \"coco\", split, f\"{coco_file_name}_corrected_coco.json\")\n",
    "        self.image_dir = os.path.join(self.DATA_DIR, \"coco\", \"images_sliced\" if self.image_type == \"sliced\" else \"images\")\n",
    "\n",
    "        self._create_directories([self.output_dir, self.bbox_vis_dir])\n",
    "\n",
    "        # Load COCO annotations and initialize augmented annotations structure\n",
    "        self.coco_dict = load_json(self.org_annotation_path)\n",
    "        self.augmented_annotations = {\n",
    "            \"images\": [],\n",
    "            \"annotations\": [],\n",
    "            \"categories\": self.coco_dict[\"categories\"]\n",
    "        }\n",
    "        self.annotation_id = 1  # Initialize annotation ID counter\n",
    "\n",
    "    def _create_directories(self, directories):\n",
    "        for directory in directories:\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    def process_images(self):\n",
    "        annotations_by_image = self._organize_annotations_by_image_id()\n",
    "        \n",
    "        for img in tqdm(self.coco_dict[\"images\"], desc=\"Processing Images\"):\n",
    "            image_path = os.path.join(self.image_dir, img[\"file_name\"])\n",
    "            if not os.path.exists(image_path):\n",
    "                print(f\"Warning: Image {img['file_name']} not found.\")\n",
    "                continue\n",
    "            \n",
    "            image = self._load_image(image_path)\n",
    "            bboxes, class_labels = self._extract_bboxes_and_labels(img[\"id\"], annotations_by_image)\n",
    "            \n",
    "            # Apply and save each augmentation type separately\n",
    "            self._apply_and_save(image, bboxes, class_labels, img[\"file_name\"], \"flip\")\n",
    "            self._apply_and_save(image, bboxes, class_labels, img[\"file_name\"], \"contrast\")\n",
    "            self._apply_and_save(image, bboxes, class_labels, img[\"file_name\"], \"noise\")\n",
    "\n",
    "    def _apply_and_save(self, image, bboxes, class_labels, filename, aug_type):\n",
    "        if aug_type == \"flip\":\n",
    "            augmentation = A.Compose([A.HorizontalFlip(p=1)], bbox_params=A.BboxParams(format='coco', label_fields=['class_labels']))\n",
    "        elif aug_type == \"contrast\":\n",
    "            augmentation = A.Compose([A.RandomBrightnessContrast(p=1)], bbox_params=A.BboxParams(format='coco', label_fields=['class_labels']))\n",
    "        elif aug_type == \"noise\":\n",
    "            augmentation = A.Compose([A.GaussNoise(var_limit=(10, 50), p=1)], bbox_params=A.BboxParams(format='coco', label_fields=['class_labels']))\n",
    "        \n",
    "        augmented = augmentation(image=image, bboxes=bboxes, class_labels=class_labels)\n",
    "        augmented_image = augmented['image']\n",
    "        augmented_bboxes = augmented['bboxes']\n",
    "\n",
    "        # Save augmented image and bbox visualization\n",
    "        save_filename = f\"{filename[:-4]}_{aug_type}.png\"\n",
    "        self._save_augmented_image(augmented_image, save_filename)\n",
    "        self._visualize_augmented_with_bboxes(augmented_image, augmented_bboxes, save_filename, aug_type)\n",
    "\n",
    "        # Save augmented annotation\n",
    "        self._save_augmented_annotation(save_filename, augmented_bboxes, class_labels, img_width=augmented_image.shape[1], img_height=augmented_image.shape[0])\n",
    "\n",
    "    def _save_augmented_annotation(self, filename, bboxes, class_labels, img_width, img_height):\n",
    "        image_entry = {\n",
    "            \"id\": len(self.augmented_annotations[\"images\"]) + 1,\n",
    "            \"file_name\": filename,\n",
    "            \"width\": img_width,\n",
    "            \"height\": img_height\n",
    "        }\n",
    "        self.augmented_annotations[\"images\"].append(image_entry)\n",
    "\n",
    "        for bbox, label in zip(bboxes, class_labels):\n",
    "            x, y, w, h = bbox\n",
    "            annotation_entry = {\n",
    "                \"id\": self.annotation_id,\n",
    "                \"image_id\": image_entry[\"id\"],\n",
    "                \"category_id\": label,\n",
    "                \"bbox\": [x, y, w, h],\n",
    "                \"area\": w * h,\n",
    "                \"iscrowd\": 0\n",
    "            }\n",
    "            self.augmented_annotations[\"annotations\"].append(annotation_entry)\n",
    "            self.annotation_id += 1\n",
    "\n",
    "    def save_augmented_coco_json(self, output_path):\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(self.augmented_annotations, f)\n",
    "\n",
    "    def _load_image(self, image_path):\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        return cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    def _save_augmented_image(self, image, filename):\n",
    "        output_path = os.path.join(self.output_dir, filename)\n",
    "        image = image.permute(1, 2, 0).cpu().numpy()\n",
    "        image = (image * 255).astype('uint8')\n",
    "        cv2.imwrite(output_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    def _visualize_augmented_with_bboxes(self, image, bboxes, filename, aug_type):\n",
    "        # Convert image to PIL format for drawing bounding boxes\n",
    "        pil_image = Image.fromarray((image * 255).astype(np.uint8)).convert(\"L\")\n",
    "        rgb_image = Image.merge(\"RGB\", (pil_image, pil_image, pil_image))\n",
    "        \n",
    "        # Draw bounding boxes on the image\n",
    "        draw = ImageDraw.Draw(rgb_image)\n",
    "        for bbox in bboxes:\n",
    "            x_min, y_min, width, height = bbox\n",
    "            x_max, y_max = x_min + width, y_min + height\n",
    "            draw.rectangle([x_min, y_min, x_max, y_max], outline=\"lime\", width=3)\n",
    "\n",
    "        save_path = os.path.join(self.bbox_vis_dir, f\"{filename[:-4]}_{aug_type}_bbox.png\")\n",
    "        rgb_image.save(save_path)\n",
    "\n",
    "\n",
    "    def _organize_annotations_by_image_id(self):\n",
    "        annotations_by_image = {}\n",
    "        for annotation in self.coco_dict[\"annotations\"]:\n",
    "            image_id = annotation[\"image_id\"]\n",
    "            if image_id not in annotations_by_image:\n",
    "                annotations_by_image[image_id] = []\n",
    "            annotations_by_image[image_id].append(annotation)\n",
    "        return annotations_by_image\n",
    "\n",
    "    def _extract_bboxes_and_labels(self, image_id, annotations_by_image):\n",
    "        bboxes, class_labels = [], []\n",
    "        if image_id in annotations_by_image:\n",
    "            for annotation in annotations_by_image[image_id]:\n",
    "                x, y, w, h = annotation[\"bbox\"]\n",
    "                bboxes.append([x, y, w, h])\n",
    "                class_labels.append(annotation[\"category_id\"])\n",
    "        return bboxes, class_labels\n",
    "\n",
    "\n",
    "def plot_augmented_bboxes_coco(annotation: dict, img_dir: str, save_dir: str, aug_type: str):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    for img in tqdm(annotation[\"images\"], desc=f\"Plotting {aug_type} augmented images with bounding boxes\"):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(12, 9), constrained_layout=True)\n",
    "        mono_img = Image.open(os.path.join(img_dir, img[\"file_name\"])).convert(\"L\")\n",
    "        rgb_img = Image.merge(\"RGB\", (mono_img, mono_img, mono_img))\n",
    "\n",
    "        for ann in annotation[\"annotations\"]:\n",
    "            if ann[\"image_id\"] == img[\"id\"]:\n",
    "                xywh = ann[\"bbox\"]\n",
    "                xyxy = [xywh[0], xywh[1], xywh[0] + xywh[2], xywh[1] + xywh[3]]\n",
    "                ImageDraw.Draw(rgb_img).rectangle(xyxy, width=3, outline=\"lime\")\n",
    "\n",
    "        ax.axis(\"off\")\n",
    "        ax.imshow(rgb_img)\n",
    "\n",
    "        save_path = os.path.join(save_dir, f\"{img['file_name'][:-4]}_{aug_type}_bbox.png\")\n",
    "        fig.savefig(save_path)\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_coco_as_dataframe(coco_path):\n",
    "    with open(coco_path, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    categories = {cat[\"id\"]: cat[\"name\"] for cat in coco_data[\"categories\"]}\n",
    "\n",
    "    data = []\n",
    "    for ann in coco_data[\"annotations\"]:\n",
    "        image_id = ann[\"image_id\"]\n",
    "        category_id = ann[\"category_id\"]\n",
    "        data.append({\n",
    "            \"image_id\": image_id,\n",
    "            \"category_id\": category_id,\n",
    "            \"class_name\": categories[category_id],\n",
    "            \"bbox_x\": ann[\"bbox\"][0],\n",
    "            \"bbox_y\": ann[\"bbox\"][1],\n",
    "            \"bbox_width\": ann[\"bbox\"][2],\n",
    "            \"bbox_height\": ann[\"bbox\"][3]\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentationAnalyzer:\n",
    "    def __init__(self, original_data, augmented_data):\n",
    "        self.original_data = original_data\n",
    "        self.augmented_data = augmented_data\n",
    "\n",
    "    def plot_class_distribution(self):\n",
    "        original_counts = self.original_data['class_name'].value_counts()\n",
    "        augmented_counts = self.augmented_data['class_name'].value_counts()\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(original_counts.index, original_counts.values, alpha=0.7, label=\"Original\")\n",
    "        plt.bar(augmented_counts.index, augmented_counts.values, alpha=0.7, label=\"Augmented\")\n",
    "        plt.xlabel(\"Class\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.title(\"Class Distribution Comparison\")\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for grayscale-friendly augmentations\n",
    "config = {\n",
    "    \"DATA_DIR\": \"../data\",\n",
    "    \"AUGMENTATION_PATH\": \"../data/augmentation\",\n",
    "    \"VISUALIZATION_DIR\": \"../data/bbox_vis\",\n",
    "    \"augmentation_params\": {\n",
    "        \"horizontal_flip\": 0.5,\n",
    "        \"brightness_contrast\": 0.5,\n",
    "        \"blur\": 3,\n",
    "        \"noise\": 0.3,\n",
    "        \"normalize\": True\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Original COCO file not found.\n"
     ]
    }
   ],
   "source": [
    "def run():\n",
    "    # Verify if the original COCO file exists\n",
    "    if not os.path.exists(config[\"DATA_DIR\"] + \"/coco/train/cassette1_train_corrected_coco.json\"):\n",
    "        print(\"Error: Original COCO file not found.\")\n",
    "        return\n",
    "    \n",
    "    # Augmentation\n",
    "    augmentor_original = ImageAugmentor(coco_file_name=coco_file_name, config=config, split=\"train\", image_type=\"original\")\n",
    "    augmentor_sliced = ImageAugmentor(coco_file_name=coco_file_name, config=config, split=\"train\", image_type=\"sliced\")\n",
    "    augmentor_original.process_images()\n",
    "    augmentor_sliced.process_images()\n",
    "\n",
    "    # Save augmented COCO JSON files\n",
    "    augmentor_original.save_augmented_coco_json(\"./data/augmentation/original_images/train_annotations_augmented_original.json\")\n",
    "    augmentor_sliced.save_augmented_coco_json(\"./data/augmentation/sliced_images/train_annotations_augmented_sliced.json\")\n",
    "\n",
    "    # Load original and augmented data for analysis\n",
    "    original_data = load_coco_as_dataframe(\"./data/coco/train/cassette1_train_corrected_coco.json\")\n",
    "    augmented_data_path = \"./data/augmentation/original_images/train_annotations_augmented_original.json\"\n",
    "    \n",
    "    if not os.path.exists(augmented_data_path):\n",
    "        print(f\"Error: Augmented data not found at {augmented_data_path}.\")\n",
    "        return\n",
    "\n",
    "    augmented_data = load_coco_as_dataframe(augmented_data_path)\n",
    "\n",
    "    # Analysis\n",
    "    analyzer = AugmentationAnalyzer(original_data, augmented_data)\n",
    "    analyzer.plot_class_distribution()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MITI_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
