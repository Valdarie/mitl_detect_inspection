{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import albumentations as A \n",
    "from sahi.utils.file import load_json, save_json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "..\\testy\\coco\\val\\cassette_val_corrected_coco.json\n"
     ]
    }
   ],
   "source": [
    "coco_file_name  = \"cassette_val\"\n",
    "\n",
    "# Determine target split from coco_file_name\n",
    "target_split = None\n",
    "if \"train\" in coco_file_name.lower():\n",
    "    target_split = \"train\"\n",
    "elif \"test\" in coco_file_name.lower():\n",
    "    target_split = \"test\"\n",
    "elif \"val\" in coco_file_name.lower():\n",
    "    target_split = \"val\"\n",
    "if not target_split:\n",
    "    raise ValueError(\"Unable to determine target split from coco_file_name.\")\n",
    "\n",
    "print(target_split)\n",
    "\n",
    "DATA_DIR = os.path.join(\"..\", \"testy\")\n",
    "COCO_DIR = os.path.join(DATA_DIR, \"coco\")\n",
    "\n",
    "ORG_ANNOTATION_PATH = os.path.join(DATA_DIR, \"coco\",target_split, f\"{coco_file_name}_corrected_coco.json\")\n",
    "SLC_ANNOTATION_PATH = os.path.join(DATA_DIR, \"coco\",target_split, f\"{coco_file_name}_sliced_coco.json\")\n",
    "\n",
    "AUGMENTATION_PATH = os.path.join(COCO_DIR, \"augmentated\") # Folder for all augmentations ./data/coco/augmentated\n",
    "\n",
    "print(ORG_ANNOTATION_PATH)\n",
    "\n",
    "#IMAGE_DIR = os.path.join(COCO_DIR, \"images\")\n",
    "IMAGE_DIR = os.path.join(COCO_DIR, \"images\")\n",
    "NEW_IMAGE_DIR = os.path.join(COCO_DIR, \"images\", \"png\") #for saving new original images (untouched)\n",
    "SLICED_IMAGE_DIR = os.path.join(COCO_DIR, \"images_sliced\",coco_file_name)\n",
    "\n",
    "BBOX_VISUALIZATION_DIR = os.path.join(DATA_DIR, \"bbox_vis\", coco_file_name)\n",
    "BBOX_SAVE_DIR = os.path.join(BBOX_VISUALIZATION_DIR,\"each\") #Place to savea each of the before augmented bounding boxes\n",
    "\n",
    "os.path.exists(DATA_DIR)\n",
    "os.path.exists(COCO_DIR)\n",
    "\n",
    "os.path.exists(ORG_ANNOTATION_PATH)\n",
    "os.path.exists(IMAGE_DIR)\n",
    "os.path.exists(BBOX_VISUALIZATION_DIR)\n",
    "\n",
    "os.makedirs(BBOX_SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(NEW_IMAGE_DIR, exist_ok=True)\n",
    "os.makedirs(AUGMENTATION_PATH,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'images': [{'width': 4096,\n",
       "   'height': 2000,\n",
       "   'id': 4,\n",
       "   'file_name': '01BN02.bmp'}],\n",
       " 'annotations': [{'id': 98,\n",
       "   'image_id': 4,\n",
       "   'category_id': 5,\n",
       "   'segmentation': [],\n",
       "   'bbox': [2214.833880112831,\n",
       "    223.5076988929449,\n",
       "    21.737717054118985,\n",
       "    45.54569287529642],\n",
       "   'ignore': 0,\n",
       "   'iscrowd': 0,\n",
       "   'area': 990.0593847569965},\n",
       "  {'id': 99,\n",
       "   'image_id': 4,\n",
       "   'category_id': 5,\n",
       "   'segmentation': [],\n",
       "   'bbox': [2729.2931837269757,\n",
       "    203.84024060588504,\n",
       "    28.983622738824923,\n",
       "    38.29978719059021],\n",
       "   'ignore': 0,\n",
       "   'iscrowd': 0,\n",
       "   'area': 1110.066582909346},\n",
       "  {'id': 100,\n",
       "   'image_id': 4,\n",
       "   'category_id': 5,\n",
       "   'segmentation': [],\n",
       "   'bbox': [1882.5573479998739,\n",
       "    603.4001826482585,\n",
       "    12.421552602353332,\n",
       "    22.772846437648226],\n",
       "   'ignore': 0,\n",
       "   'iscrowd': 0,\n",
       "   'area': 282.87410993056216},\n",
       "  {'id': 101,\n",
       "   'image_id': 4,\n",
       "   'category_id': 7,\n",
       "   'segmentation': [],\n",
       "   'bbox': [2414.76780379523,\n",
       "    623.8160249415288,\n",
       "    6.427339063585387,\n",
       "    8.764553268525148],\n",
       "   'ignore': 0,\n",
       "   'iscrowd': 0,\n",
       "   'area': 56.33275559766667},\n",
       "  {'id': 102,\n",
       "   'image_id': 4,\n",
       "   'category_id': 6,\n",
       "   'segmentation': [],\n",
       "   'bbox': [3139.4239184467547,\n",
       "    332.38546483295534,\n",
       "    32.04670115714252,\n",
       "    28.095738000782404],\n",
       "   'ignore': 0,\n",
       "   'iscrowd': 0,\n",
       "   'area': 900.3757195004466},\n",
       "  {'id': 103,\n",
       "   'image_id': 4,\n",
       "   'category_id': 6,\n",
       "   'segmentation': [],\n",
       "   'bbox': [2961.600279059792,\n",
       "    195.73355615829885,\n",
       "    30.11285479358514,\n",
       "    30.112854793584418],\n",
       "   'ignore': 0,\n",
       "   'iscrowd': 0,\n",
       "   'area': 906.7840238195217},\n",
       "  {'id': 104,\n",
       "   'image_id': 4,\n",
       "   'category_id': 6,\n",
       "   'segmentation': [],\n",
       "   'bbox': [3043.714087106246,\n",
       "    1372.4790158859523,\n",
       "    41.677155586700536,\n",
       "    25.006293352020922],\n",
       "   'ignore': 0,\n",
       "   'iscrowd': 0,\n",
       "   'area': 1042.1911786788512},\n",
       "  {'id': 105,\n",
       "   'image_id': 4,\n",
       "   'category_id': 6,\n",
       "   'segmentation': [],\n",
       "   'bbox': [3017.1443808445238,\n",
       "    1838.294145123866,\n",
       "    50.19751808660163,\n",
       "    12.01912404890436],\n",
       "   'ignore': 0,\n",
       "   'iscrowd': 0,\n",
       "   'area': 603.3301968299852},\n",
       "  {'id': 106,\n",
       "   'image_id': 4,\n",
       "   'category_id': 6,\n",
       "   'segmentation': [],\n",
       "   'bbox': [2444.0108244557337,\n",
       "    1878.8898621270523,\n",
       "    39.33491657411967,\n",
       "    13.456681985881989],\n",
       "   'ignore': 0,\n",
       "   'iscrowd': 0,\n",
       "   'area': 529.317463279127},\n",
       "  {'id': 107,\n",
       "   'image_id': 4,\n",
       "   'category_id': 6,\n",
       "   'segmentation': [],\n",
       "   'bbox': [2000.9754483051242,\n",
       "    1856.1170156894027,\n",
       "    41.40517534117767,\n",
       "    15.526940752942256],\n",
       "   'ignore': 0,\n",
       "   'iscrowd': 0,\n",
       "   'area': 642.8957043876513},\n",
       "  {'id': 108,\n",
       "   'image_id': 4,\n",
       "   'category_id': 9,\n",
       "   'segmentation': [],\n",
       "   'bbox': [2059.7017886317535,\n",
       "    1559.6596085737049,\n",
       "    31.527887813377603,\n",
       "    23.94523125066712],\n",
       "   'ignore': 0,\n",
       "   'iscrowd': 0,\n",
       "   'area': 754.9425645364165},\n",
       "  {'id': 109,\n",
       "   'image_id': 4,\n",
       "   'category_id': 6,\n",
       "   'segmentation': [],\n",
       "   'bbox': [1577.0431440518012,\n",
       "    1827.751590298049,\n",
       "    11.85288946908023,\n",
       "    16.681844437964866],\n",
       "   'ignore': 0,\n",
       "   'iscrowd': 0,\n",
       "   'area': 197.72805826358837},\n",
       "  {'id': 110,\n",
       "   'image_id': 4,\n",
       "   'category_id': 6,\n",
       "   'segmentation': [],\n",
       "   'bbox': [942.0450559567693,\n",
       "    1916.0820608772663,\n",
       "    47.59524905468483,\n",
       "    20.040104865130388],\n",
       "   'ignore': 0,\n",
       "   'iscrowd': 0,\n",
       "   'area': 953.813782137882},\n",
       "  {'id': 111,\n",
       "   'image_id': 4,\n",
       "   'category_id': 6,\n",
       "   'segmentation': [],\n",
       "   'bbox': [923.2574576457093,\n",
       "    1777.0538333754237,\n",
       "    16.282585202918646,\n",
       "    30.060157297695437],\n",
       "   'ignore': 0,\n",
       "   'iscrowd': 0,\n",
       "   'area': 489.45707241286266},\n",
       "  {'id': 112,\n",
       "   'image_id': 4,\n",
       "   'category_id': 7,\n",
       "   'segmentation': [],\n",
       "   'bbox': [873.8602257766653,\n",
       "    1490.1689155129952,\n",
       "    5.706946781408915,\n",
       "    8.34092221898203],\n",
       "   'ignore': 0,\n",
       "   'iscrowd': 0,\n",
       "   'area': 47.601199211601596},\n",
       "  {'id': 113,\n",
       "   'image_id': 4,\n",
       "   'category_id': 9,\n",
       "   'segmentation': [],\n",
       "   'bbox': [883.9571316206959,\n",
       "    1331.6913933523301,\n",
       "    43.46059471995986,\n",
       "    71.99532862700448],\n",
       "   'ignore': 0,\n",
       "   'iscrowd': 0,\n",
       "   'area': 3128.9597991885657},\n",
       "  {'id': 114,\n",
       "   'image_id': 4,\n",
       "   'category_id': 7,\n",
       "   'segmentation': [],\n",
       "   'bbox': [1066.8418007680132,\n",
       "    588.0255901600613,\n",
       "    9.179005312755905,\n",
       "    12.371702812844687],\n",
       "   'ignore': 0,\n",
       "   'iscrowd': 0,\n",
       "   'area': 113.55992584693855},\n",
       "  {'id': 115,\n",
       "   'image_id': 4,\n",
       "   'category_id': 9,\n",
       "   'segmentation': [],\n",
       "   'bbox': [1042.8496774246828,\n",
       "    615.4772707374756,\n",
       "    55.79347377223836,\n",
       "    204.95561793883405],\n",
       "   'ignore': 0,\n",
       "   'iscrowd': 0,\n",
       "   'area': 11435.185893943242},\n",
       "  {'id': 116,\n",
       "   'image_id': 4,\n",
       "   'category_id': 9,\n",
       "   'segmentation': [],\n",
       "   'bbox': [1155.5752672910414,\n",
       "    607.5067744842988,\n",
       "    63.76397002541518,\n",
       "    228.86710669836472],\n",
       "   'ignore': 0,\n",
       "   'iscrowd': 0,\n",
       "   'area': 14593.475331318026},\n",
       "  {'id': 117,\n",
       "   'image_id': 4,\n",
       "   'category_id': 0,\n",
       "   'segmentation': [],\n",
       "   'bbox': [1333.9730532212661,\n",
       "    434.93307532387,\n",
       "    88.65871504309557,\n",
       "    165.65180968578238],\n",
       "   'ignore': 0,\n",
       "   'iscrowd': 0,\n",
       "   'area': 14686.47659130488},\n",
       "  {'id': 118,\n",
       "   'image_id': 4,\n",
       "   'category_id': 7,\n",
       "   'segmentation': [],\n",
       "   'bbox': [1154.1381840756967,\n",
       "    49.66580185497679,\n",
       "    6.427339063585241,\n",
       "    12.854678127170462],\n",
       "   'ignore': 0,\n",
       "   'iscrowd': 0,\n",
       "   'area': 82.62137487657748},\n",
       "  {'id': 119,\n",
       "   'image_id': 4,\n",
       "   'category_id': 7,\n",
       "   'segmentation': [],\n",
       "   'bbox': [3257.030091781571,\n",
       "    1020.0990175191394,\n",
       "    22.240887685365742,\n",
       "    22.240887685366033],\n",
       "   'ignore': 0,\n",
       "   'iscrowd': 0,\n",
       "   'area': 494.65708503305996},\n",
       "  {'id': 120,\n",
       "   'image_id': 4,\n",
       "   'category_id': 7,\n",
       "   'segmentation': [],\n",
       "   'bbox': [3330.7030322393457,\n",
       "    1124.3531785442922,\n",
       "    7.645305141844437,\n",
       "    8.340332882012405],\n",
       "   'ignore': 0,\n",
       "   'iscrowd': 0,\n",
       "   'area': 63.76438986754367},\n",
       "  {'id': 121,\n",
       "   'image_id': 4,\n",
       "   'category_id': 7,\n",
       "   'segmentation': [],\n",
       "   'bbox': [3164.670790887308,\n",
       "    870.6256913339246,\n",
       "    6.1712728790252,\n",
       "    5.69655958063791],\n",
       "   'ignore': 0,\n",
       "   'iscrowd': 0,\n",
       "   'area': 35.1550236437419},\n",
       "  {'id': 122,\n",
       "   'image_id': 4,\n",
       "   'category_id': 7,\n",
       "   'segmentation': [],\n",
       "   'bbox': [1677.8210677740008,\n",
       "    926.6261497377964,\n",
       "    4.17016644100601,\n",
       "    6.528409868713643],\n",
       "   'ignore': 0,\n",
       "   'iscrowd': 0,\n",
       "   'area': 27.22455574764209},\n",
       "  {'id': 123,\n",
       "   'image_id': 4,\n",
       "   'category_id': 7,\n",
       "   'segmentation': [],\n",
       "   'bbox': [1618.1910591263832,\n",
       "    1012.4121521691746,\n",
       "    3.422521247342811,\n",
       "    5.637093819153023],\n",
       "   'ignore': 0,\n",
       "   'iscrowd': 0,\n",
       "   'area': 19.293073369316055},\n",
       "  {'id': 124,\n",
       "   'image_id': 4,\n",
       "   'category_id': 7,\n",
       "   'segmentation': [],\n",
       "   'bbox': [2734.8370710785075,\n",
       "    1347.2817904399178,\n",
       "    6.189951795467059,\n",
       "    12.969422809548519],\n",
       "   'ignore': 0,\n",
       "   'iscrowd': 0,\n",
       "   'area': 80.28010200613629},\n",
       "  {'id': 125,\n",
       "   'image_id': 4,\n",
       "   'category_id': 7,\n",
       "   'segmentation': [],\n",
       "   'bbox': [1953.9045000757992,\n",
       "    1384.8410406097285,\n",
       "    10.699773817877867,\n",
       "    17.508720792890813],\n",
       "   'ignore': 0,\n",
       "   'iscrowd': 0,\n",
       "   'area': 187.33935232430693},\n",
       "  {'id': 126,\n",
       "   'image_id': 4,\n",
       "   'category_id': 6,\n",
       "   'segmentation': [],\n",
       "   'bbox': [1367.880142997596,\n",
       "    278.27019267822004,\n",
       "    22.16311269118538,\n",
       "    163.76077710709407],\n",
       "   'ignore': 0,\n",
       "   'iscrowd': 0,\n",
       "   'area': 3629.448557420617}],\n",
       " 'categories': [{'id': 0, 'name': 'blocked_valve'},\n",
       "  {'id': 1, 'name': 'bubble'},\n",
       "  {'id': 2, 'name': 'chip_crack'},\n",
       "  {'id': 3, 'name': 'excessive_flash'},\n",
       "  {'id': 4, 'name': 'improper_welding'},\n",
       "  {'id': 5, 'name': 'light_stain'},\n",
       "  {'id': 6, 'name': 'line_crack'},\n",
       "  {'id': 7, 'name': 'particle_material'},\n",
       "  {'id': 8, 'name': 'residue_stain'},\n",
       "  {'id': 9, 'name': 'unknown'},\n",
       "  {'id': 10, 'name': 'welding_blob'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_dict = load_json(ORG_ANNOTATION_PATH)\n",
    "[img.update({\"file_name\": img[\"file_name\"].split(\"/\")[-1]}) for img in coco_dict[\"images\"]]\n",
    "save_json(coco_dict, save_path=ORG_ANNOTATION_PATH)\n",
    "\n",
    "coco_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in coco_dict[\"images\"]:\n",
    "    # Open and convert the image to grayscale\n",
    "    mono_img = Image.open(os.path.join(IMAGE_DIR, img[\"file_name\"])).convert(\"L\")\n",
    "    \n",
    "    # Save the grayscale image as .png\n",
    "    png_file_name = img[\"file_name\"].replace(\".bmp\", \".png\")\n",
    "    mono_img.save(os.path.join(NEW_IMAGE_DIR, png_file_name), format=\"PNG\")\n",
    "    \n",
    "    # Convert grayscale image to RGB\n",
    "    rgb_img = Image.merge(\"RGB\", (mono_img, mono_img, mono_img))\n",
    "\n",
    "    # Visualize bounding boxes on the RGB image\n",
    "    for ann_ind in range(len(coco_dict[\"annotations\"])):\n",
    "        if coco_dict[\"annotations\"][ann_ind][\"image_id\"] == img[\"id\"]:\n",
    "            xywh = coco_dict[\"annotations\"][ann_ind][\"bbox\"]\n",
    "            xyxy = [xywh[0], xywh[1], xywh[0] + xywh[2], xywh[1] + xywh[3]]\n",
    "            ImageDraw.Draw(rgb_img).rectangle(xyxy, width=5, outline=\"lime\")\n",
    "\n",
    "    # Display and save the image with bounding boxes as .png\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 9), constrained_layout=True)\n",
    "    ax.axis(\"off\")\n",
    "    ax.imshow(rgb_img)\n",
    "    fig.savefig(os.path.join(BBOX_SAVE_DIR, png_file_name)) #save each of the image original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\testy\\coco\\val\\cassette_val_sliced_coco.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'images': [{'height': 640,\n",
       "   'width': 640,\n",
       "   'id': 27,\n",
       "   'file_name': '01BN02_0_1024_1360_1664_2000.png'}],\n",
       " 'annotations': [{'iscrowd': 0,\n",
       "   'image_id': 27,\n",
       "   'bbox': [553.0431440518012,\n",
       "    467.751590298049,\n",
       "    11.85288946908031,\n",
       "    16.681844437964855],\n",
       "   'segmentation': [[553, 467, 553, 484, 564, 484, 564, 467]],\n",
       "   'category_id': 6,\n",
       "   'id': 45,\n",
       "   'area': 197}],\n",
       " 'categories': [{'id': 0, 'name': 'blocked_valve'},\n",
       "  {'id': 1, 'name': 'bubble'},\n",
       "  {'id': 2, 'name': 'chip_crack'},\n",
       "  {'id': 3, 'name': 'excessive_flash'},\n",
       "  {'id': 4, 'name': 'improper_welding'},\n",
       "  {'id': 5, 'name': 'light_stain'},\n",
       "  {'id': 6, 'name': 'line_crack'},\n",
       "  {'id': 7, 'name': 'particle_material'},\n",
       "  {'id': 8, 'name': 'residue_stain'},\n",
       "  {'id': 9, 'name': 'unknown'},\n",
       "  {'id': 10, 'name': 'welding_blob'}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slc_dict= load_json(SLC_ANNOTATION_PATH)\n",
    "print(SLC_ANNOTATION_PATH)\n",
    "\n",
    "slc_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in slc_dict[\"images\"]:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 9), constrained_layout=True)\n",
    "    \n",
    "    # Open the sliced image file in grayscale, convert it to RGB\n",
    "    sliced_img_path = os.path.join(SLICED_IMAGE_DIR, img[\"file_name\"])\n",
    "    mono_img = Image.open(sliced_img_path).convert(\"L\")\n",
    "    rgb_img = Image.merge(\"RGB\", (mono_img, mono_img, mono_img))\n",
    "    \n",
    "    # Iterate over all annotations for this specific image\n",
    "    for annotation in slc_dict[\"annotations\"]:\n",
    "        if annotation[\"image_id\"] == img[\"id\"]:\n",
    "            # Extract and convert bounding box coordinates\n",
    "            xywh = annotation[\"bbox\"]\n",
    "            xyxy = [xywh[0], xywh[1], xywh[0] + xywh[2], xywh[1] + xywh[3]]\n",
    "            \n",
    "            # Draw the bounding box on the image\n",
    "            ImageDraw.Draw(rgb_img).rectangle(xyxy, width=5, outline=\"lime\")\n",
    "    \n",
    "    # Display and save the image with bounding boxes\n",
    "    ax.axis(\"off\")\n",
    "    ax.imshow(rgb_img)\n",
    "    fig.savefig(os.path.join(BBOX_SAVE_DIR, img[\"file_name\"][:-4] + \".png\")) #save each of the image to folder called Each\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [\"train\", \"test\", \"val\"]\n",
    "\n",
    "# Create 'original' and 'sliced' directories within each split\n",
    "for split in splits:\n",
    "    base_path = os.path.join(AUGMENTATION_PATH, split)\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "    \n",
    "    # Create 'original' and 'sliced' subdirectories within each split\n",
    "    os.makedirs(os.path.join(base_path, \"original\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(base_path, \"sliced\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial AUGMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### horizontal flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sliced images: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented annotations saved to ..\\testy\\coco\\augmentated\\val\\sliced\\horizontal_flip\\cassette_val_horizontal_flip.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def horizontal_flip_with_bboxes(\n",
    "    image_dir,\n",
    "    coco_annotations,\n",
    "    output_dir,\n",
    "    aug_type=\"horizontal_flip\",\n",
    "    dataset_type=\"original\",\n",
    "    mean=(0.485, 0.456, 0.406),\n",
    "    std=(0.229, 0.224, 0.225),\n",
    "    max_pixel_value=255.0\n",
    "):\n",
    "    # Set directories based on dataset_type\n",
    "    AUG_SAVE_DIR = os.path.join(AUGMENTATION_PATH, target_split, dataset_type, aug_type, \"each\")\n",
    "    AUG_VIEW_DIR = os.path.join(AUGMENTATION_PATH, target_split, dataset_type, aug_type)\n",
    "\n",
    "    os.makedirs(AUG_SAVE_DIR, exist_ok=True)\n",
    "    os.makedirs(AUG_VIEW_DIR, exist_ok=True)\n",
    "    \n",
    "    # Augmentation pipeline with normalization\n",
    "    augmentation_pipeline = A.Compose([\n",
    "        A.HorizontalFlip(p=1.0),\n",
    "        A.Normalize(mean=mean, std=std, max_pixel_value=max_pixel_value)\n",
    "    ], bbox_params=A.BboxParams(format=\"coco\", label_fields=[\"class_labels\"]))\n",
    "\n",
    "    # Use tqdm to show progress\n",
    "    for img in tqdm(coco_annotations[\"images\"], desc=f\"Processing {dataset_type} images\"):\n",
    "        file_name = img[\"file_name\"].replace(\".bmp\", \".png\")  # Replace .bmp with .png\n",
    "        image_id = img[\"id\"]\n",
    "\n",
    "        # Load image as grayscale\n",
    "        image_path = os.path.join(image_dir, file_name)\n",
    "        mono_img = Image.open(image_path).convert(\"L\")\n",
    "\n",
    "        # Convert grayscale image to numpy array for augmentation\n",
    "        image_np = np.array(mono_img)\n",
    "\n",
    "        # Get bounding boxes and labels\n",
    "        bboxes = [ann[\"bbox\"] for ann in coco_annotations[\"annotations\"] if ann[\"image_id\"] == image_id]\n",
    "        class_labels = [ann[\"category_id\"] for ann in coco_annotations[\"annotations\"] if ann[\"image_id\"] == image_id]\n",
    "\n",
    "        # Apply augmentation with normalization, including class_labels\n",
    "        augmented = augmentation_pipeline(image=image_np, bboxes=bboxes, class_labels=class_labels)\n",
    "        \n",
    "        # Rescale the augmented image and save it\n",
    "        augmented_image = (augmented[\"image\"] * np.array(std[0]) + mean[0]) * max_pixel_value\n",
    "        augmented_image = np.clip(augmented_image, 0, 255).astype(\"uint8\")\n",
    "        Image.fromarray(augmented_image).save(os.path.join(AUG_SAVE_DIR, f\"{aug_type}_{file_name}\"))\n",
    "\n",
    "        # Convert the augmented image to RGB for bounding box visualization\n",
    "        rgb_img = Image.merge(\"RGB\", (Image.fromarray(augmented_image),) * 3)\n",
    "        draw = ImageDraw.Draw(rgb_img)\n",
    "        \n",
    "        # Draw each bounding box on the RGB image\n",
    "        for bbox in augmented[\"bboxes\"]:\n",
    "            xyxy = [bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]]\n",
    "            draw.rectangle(xyxy, outline=\"lime\", width=5)\n",
    "        \n",
    "        # Save the image with colored bounding boxes\n",
    "        rgb_img.save(os.path.join(AUG_VIEW_DIR, f\"{aug_type}_{file_name}\"))\n",
    "\n",
    "    # Save the updated COCO JSON annotations\n",
    "    augmented_json_path = os.path.join(output_dir, f\"{coco_file_name}_{aug_type}.json\")\n",
    "    save_json(coco_annotations, augmented_json_path)\n",
    "    print(f\"Augmented annotations saved to {augmented_json_path}\")\n",
    "\n",
    "# Run the function for both original and sliced cases\n",
    "# horizontal_flip_with_bboxes(NEW_IMAGE_DIR, coco_dict, os.path.join(AUGMENTATION_PATH, target_split, \"original\", \"horizontal_flip\"), dataset_type=\"original\")\n",
    "horizontal_flip_with_bboxes(SLICED_IMAGE_DIR, slc_dict, os.path.join(AUGMENTATION_PATH, target_split, \"sliced\", \"horizontal_flip\"), dataset_type=\"sliced\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NEW_IMAGE_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 66\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAugmented annotations saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maugmented_json_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Run the function for both original and sliced cases\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m horizontal_flip_with_bboxes(\u001b[43mNEW_IMAGE_DIR\u001b[49m, coco_dict, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(AUGMENTATION_PATH, target_split, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhorizontal_flip\u001b[39m\u001b[38;5;124m\"\u001b[39m), dataset_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     67\u001b[0m horizontal_flip_with_bboxes(SLICED_IMAGE_DIR, slc_dict, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(AUGMENTATION_PATH, target_split, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msliced\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhorizontal_flip\u001b[39m\u001b[38;5;124m\"\u001b[39m), dataset_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msliced\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'NEW_IMAGE_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "def horizontal_flip_with_bboxes(\n",
    "    image_dir,\n",
    "    coco_annotations,\n",
    "    output_dir,\n",
    "    aug_type=\"horizontal_flip\",\n",
    "    dataset_type=\"original\",\n",
    "    mean=(0.485, 0.456, 0.406),\n",
    "    std=(0.229, 0.224, 0.225),\n",
    "    max_pixel_value=255.0\n",
    "):\n",
    "    # Set directories based on dataset_type\n",
    "    AUG_SAVE_DIR = os.path.join(AUGMENTATION_PATH, target_split, dataset_type, aug_type, \"each\")\n",
    "    AUG_VIEW_DIR = os.path.join(AUGMENTATION_PATH, target_split, dataset_type, aug_type)\n",
    "\n",
    "    os.makedirs(AUG_SAVE_DIR, exist_ok=True)\n",
    "    os.makedirs(AUG_VIEW_DIR, exist_ok=True)\n",
    "    \n",
    "    # Augmentation pipeline with normalization\n",
    "    augmentation_pipeline = A.Compose([\n",
    "        A.HorizontalFlip(p=1.0),\n",
    "        A.Normalize(mean=mean, std=std, max_pixel_value=max_pixel_value)\n",
    "    ], bbox_params=A.BboxParams(format=\"coco\", label_fields=[\"class_labels\"]))\n",
    "\n",
    "    # Use tqdm to show progress\n",
    "    for img in tqdm(coco_annotations[\"images\"], desc=f\"Processing {dataset_type} images\"):\n",
    "        file_name = img[\"file_name\"].replace(\".bmp\", \".png\")  # Replace .bmp with .png\n",
    "        image_id = img[\"id\"]\n",
    "\n",
    "        # Load image as grayscale\n",
    "        image_path = os.path.join(image_dir, file_name)\n",
    "        mono_img = Image.open(image_path).convert(\"L\")\n",
    "\n",
    "        # Convert grayscale image to numpy array for augmentation\n",
    "        image_np = np.array(mono_img)\n",
    "\n",
    "        # Get bounding boxes and labels\n",
    "        bboxes = [ann[\"bbox\"] for ann in coco_annotations[\"annotations\"] if ann[\"image_id\"] == image_id]\n",
    "        class_labels = [ann[\"category_id\"] for ann in coco_annotations[\"annotations\"] if ann[\"image_id\"] == image_id]\n",
    "\n",
    "        # Apply augmentation with normalization, including class_labels\n",
    "        augmented = augmentation_pipeline(image=image_np, bboxes=bboxes, class_labels=class_labels)\n",
    "        \n",
    "        # Rescale the augmented image and save it\n",
    "        augmented_image = (augmented[\"image\"] * np.array(std[0]) + mean[0]) * max_pixel_value\n",
    "        augmented_image = np.clip(augmented_image, 0, 255).astype(\"uint8\")\n",
    "        Image.fromarray(augmented_image).save(os.path.join(AUG_SAVE_DIR, f\"{aug_type}_{file_name}\"))\n",
    "\n",
    "        # Convert the augmented image to RGB for bounding box visualization\n",
    "        rgb_img = Image.merge(\"RGB\", (Image.fromarray(augmented_image),) * 3)\n",
    "        draw = ImageDraw.Draw(rgb_img)\n",
    "        \n",
    "        # Draw each bounding box on the RGB image\n",
    "        for bbox in augmented[\"bboxes\"]:\n",
    "            xyxy = [bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]]\n",
    "            draw.rectangle(xyxy, outline=\"lime\", width=5)\n",
    "        \n",
    "        # Save the image with colored bounding boxes\n",
    "        rgb_img.save(os.path.join(AUG_VIEW_DIR, f\"{aug_type}_{file_name}\"))\n",
    "\n",
    "    # Save the updated COCO JSON annotations\n",
    "    augmented_json_path = os.path.join(output_dir, f\"{coco_file_name}_{aug_type}.json\")\n",
    "    save_json(coco_annotations, augmented_json_path)\n",
    "    print(f\"Augmented annotations saved to {augmented_json_path}\")\n",
    "\n",
    "# Run the function for both original and sliced cases\n",
    "horizontal_flip_with_bboxes(NEW_IMAGE_DIR, coco_dict, os.path.join(AUGMENTATION_PATH, target_split, \"original\", \"horizontal_flip\"), dataset_type=\"original\")\n",
    "horizontal_flip_with_bboxes(SLICED_IMAGE_DIR, slc_dict, os.path.join(AUGMENTATION_PATH, target_split, \"sliced\", \"horizontal_flip\"), dataset_type=\"sliced\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MITI_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
